{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XpCV4auVKtfh",
        "outputId": "b9d86c7b-48eb-441e-f8b3-ec55f1d7e2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio transformers torch psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZeGplJcvK2Yk",
        "outputId": "8c31e7ad-74a2-43ce-cebe-4736e9cdcd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
            "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface_hub[hf_xet])\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.4.26)\n",
            "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-xet\n",
            "Successfully installed hf-xet-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpmWtdfmK2VL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vX8AnCzK2SK"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LYs09EeK2P4"
      },
      "outputs": [],
      "source": [
        "# Helper Functions (assumed from prior code)\n",
        "def clean_numeric_input(value):\n",
        "    try:\n",
        "        cleaned = re.sub(r'[^\\d.]', '', str(value))\n",
        "        return float(cleaned)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def build_prompt(history, user_input):\n",
        "    convo = \"\"\n",
        "    if history:\n",
        "        for msg in history[-5:]:\n",
        "            convo += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a friendly and detailed personal finance coach. Provide clear, actionable, and specific advice tailored to the user's question. Avoid repetitive phrases, redundant sentences, or generic responses. Ensure the response is concise, practical, and directly addresses the query. Do not include the word 'Coach' or repeat the user's input verbatim. If the user asks about saving for goals, include specific examples, reference goal-setting commands, and suggest financial tools. Use the following examples as a guide for tone and structure:\n",
        "\n",
        "Example 1:\n",
        "User: How can I save money on a tight budget?\n",
        "Response: Track every expense to identify savings opportunities. Follow the 50/30/20 rule: 50% for needs, 30% for wants, 20% for savings. Cancel unused subscriptions and reduce dining out.\n",
        "\n",
        "Example 2:\n",
        "User: I want to buy a car in 2 years, how to save?\n",
        "Response: Estimate the car’s cost (e.g., $20,000) and divide by 24 to set a monthly savings target of about $833. Use 'add goal car 20000 24' to track it. Open a high-yield savings account to earn interest and automate monthly transfers. Cut non-essential expenses or consider a side hustle.\n",
        "\n",
        "Example 3:\n",
        "User: How can I save for goals?\n",
        "Response: Define each goal, like a vacation or home, and estimate its cost. Use 'add goal vacation 1000 12' to set a target and timeframe. Divide the cost by the months to find your savings target. Save in a high-yield savings account and automate transfers to stay consistent.\n",
        "\n",
        "Conversation so far:\n",
        "{convo}\n",
        "User: {user_input}\n",
        "Response:\n",
        "\"\"\"\n",
        "    return prompt.strip()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y48IMg9MX025"
      },
      "outputs": [],
      "source": [
        "def deduplicate_response(text):\n",
        "    # Extract text after \"Response:\" and remove prompt artifacts\n",
        "    text = text.split(\"Response:\")[-1].strip() if \"Response:\" in text else text.strip()\n",
        "\n",
        "    # Split into sentences, handling T5 output quirks\n",
        "    lines = [line.strip() for line in re.split(r'[.!?]\\s+', text) if line.strip()]\n",
        "    seen = set()\n",
        "    filtered = []\n",
        "    for line in lines:\n",
        "        line_clean = line.lower().strip()\n",
        "        if line_clean and line_clean not in seen:\n",
        "            filtered.append(line)\n",
        "            seen.add(line_clean)\n",
        "\n",
        "    # Join sentences with proper punctuation\n",
        "    result = '. '.join(filtered)\n",
        "    if result and not result.endswith('.'):\n",
        "        result += '.'\n",
        "    return result if result else \"Please clarify your request.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fPomVaoK2Nl"
      },
      "outputs": [],
      "source": [
        "# FinanceAgent class (partial, with required methods)\n",
        "class FinanceAgent:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "        self.goals = {}\n",
        "        self.budget = {\"income\": 0.0, \"expenses\": 0.0}\n",
        "\n",
        "    def reset(self):\n",
        "        self.history = []\n",
        "        self.goals = {}\n",
        "        self.budget = {\"income\": 0.0, \"expenses\": 0.0}\n",
        "        return \"Session reset. Welcome to your Personal Finance Coach! Try 'add goal vacation 1000 12' or ask 'How can I save for goals?'\"\n",
        "\n",
        "    def add_goal(self, name, amount, timeframe=None):\n",
        "        amount_val = clean_numeric_input(amount)\n",
        "        if amount_val is None or not name.strip():\n",
        "            return \"Invalid input. Use 'add goal name amount [months]' (e.g., add goal vacation 1000 12).\"\n",
        "        goal_data = {\"amount\": amount_val, \"date_added\": datetime.now().strftime(\"%Y-%m-%d\")}\n",
        "        if timeframe:\n",
        "            tf = clean_numeric_input(timeframe)\n",
        "            if tf and tf > 0:\n",
        "                goal_data[\"monthly_saving\"] = amount_val / tf\n",
        "        self.goals[name.lower()] = goal_data\n",
        "        msg = f\"Goal '{name}' added with target ${amount_val:.2f}.\"\n",
        "        if \"monthly_saving\" in goal_data:\n",
        "            msg += f\" Save ${goal_data['monthly_saving']:.2f}/month for {tf} months.\"\n",
        "        return msg\n",
        "\n",
        "    def list_goals(self):\n",
        "        if not self.goals:\n",
        "            return \"No goals set. Try 'add goal vacation 1000 12' to start.\"\n",
        "        s = \"Your goals:\\n\"\n",
        "        for name, data in self.goals.items():\n",
        "            s += f\"- {name}: ${data['amount']:.2f} (Added {data['date_added']})\"\n",
        "            if \"monthly_saving\" in data:\n",
        "                s += f\", Monthly: ${data['monthly_saving']:.2f}\"\n",
        "            s += \"\\n\"\n",
        "        return s.strip()\n",
        "\n",
        "    def estimate_savings(self, income, expenses):\n",
        "        income_val = clean_numeric_input(income)\n",
        "        expenses_val = clean_numeric_input(expenses)\n",
        "        if income_val is None or expenses_val is None:\n",
        "            return \"Enter valid numbers (e.g., estimate savings 3000 2500).\"\n",
        "        savings = income_val - expenses_val\n",
        "        self.budget[\"income\"] = income_val\n",
        "        self.budget[\"expenses\"] = expenses_val\n",
        "        return f\"Savings: ${savings:.2f}/month\" if savings > 0 else \"Expenses exceed income.\"\n",
        "\n",
        "    def get_budget_summary(self):\n",
        "        if self.budget[\"income\"] == 0 and self.budget[\"expenses\"] == 0:\n",
        "            return \"No budget data yet. Try 'estimate savings 3000 2500' to set income and expenses.\"\n",
        "        savings = self.budget[\"income\"] - self.budget[\"expenses\"]\n",
        "        return f\"Income: ${self.budget['income']:.2f}\\nExpenses: ${self.budget['expenses']:.2f}\\nSavings: ${savings:.2f}/month\"\n",
        "\n",
        "    def respond(self, user_input):\n",
        "        if not model:\n",
        "            return \"Model failed to load. Check logs and ensure dependencies are installed.\"\n",
        "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        lower = user_input.lower().strip()\n",
        "        logger.debug(f\"Processed input: {lower}\")\n",
        "\n",
        "        if lower.startswith(\"add goal\"):\n",
        "            match = re.match(r\"add goal\\s+(.+?)\\s+(\\d*\\.?\\d*)\\s*(\\d*\\.?\\d*)?\", lower)\n",
        "            if match:\n",
        "                name, amount, timeframe = match.groups()\n",
        "                msg = self.add_goal(name, amount, timeframe or None)\n",
        "                self.history.append({\"role\": \"coach\", \"content\": msg})\n",
        "                return msg\n",
        "            return \"Invalid format. Use 'add goal name amount [months]'.\"\n",
        "\n",
        "        if lower.startswith(\"list goals\"):\n",
        "            msg = self.list_goals()\n",
        "            self.history.append({\"role\": \"coach\", \"content\": msg})\n",
        "            return msg\n",
        "\n",
        "        if lower.startswith(\"estimate savings\"):\n",
        "            match = re.match(r\"estimate savings\\s+(\\d*\\.?\\d*)\\s+(\\d*\\.?\\d*)\", lower)\n",
        "            if match:\n",
        "                income, expenses = match.groups()\n",
        "                msg = self.estimate_savings(income, expenses)\n",
        "                self.history.append({\"role\": \"coach\", \"content\": msg})\n",
        "                return msg\n",
        "            return \"Invalid format. Use 'estimate savings income expenses'.\"\n",
        "\n",
        "        if \"save for goals\" in lower:\n",
        "            msg = \"Define each goal, like a vacation or home, and estimate its cost. Use 'add goal vacation 1000 12' to set a target and timeframe. Divide the cost by the months to find your savings target. Save in a high-yield savings account and automate transfers.\"\n",
        "            if self.goals:\n",
        "                msg += \" Your current goals include:\\n\" + self.list_goals()\n",
        "            self.history.append({\"role\": \"coach\", \"content\": msg})\n",
        "            return msg\n",
        "\n",
        "        if \"buy a car\" in lower and \"save\" in lower:\n",
        "            msg = \"Estimate the car’s cost (e.g., $20,000) and divide by 24 to set a monthly savings target of about $833. Use 'add goal car 20000 24' to track it. Open a high-yield savings account to earn interest and automate monthly transfers. Cut non-essential expenses or consider a side hustle.\"\n",
        "            if self.goals:\n",
        "                msg += \" Your current goals include:\\n\" + self.list_goals()\n",
        "            self.history.append({\"role\": \"coach\", \"content\": msg})\n",
        "            return msg\n",
        "\n",
        "        prompt = build_prompt(self.history, user_input)\n",
        "        logger.debug(f\"Prompt: {prompt}\")\n",
        "        try:\n",
        "            output = model(\n",
        "                prompt,\n",
        "                max_length=300,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_k=50,\n",
        "                num_beams=5,\n",
        "                early_stopping=True\n",
        "            )[0]['generated_text'].strip()\n",
        "            logger.debug(f\"Raw model output: {output}\")\n",
        "\n",
        "            if \"Response:\" in output:\n",
        "                output = output.split(\"Response:\")[-1].strip()\n",
        "            else:\n",
        "                output = output.strip()\n",
        "\n",
        "            output = deduplicate_response(output)\n",
        "            if not output or output.lower() in [\"coach\", \"response\"]:\n",
        "                output = \"Please clarify your request.\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model error: {e}\")\n",
        "            output = \"Error generating response. Check logs.\"\n",
        "\n",
        "        self.history.append({\"role\": \"coach\", \"content\": output})\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy6m-GUjK2Kz",
        "outputId": "750401c5-f20a-495b-b5bb-8a3c5b5a4bbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Gradio UI logic\n",
        "def user_interaction(user_input, chat_history, agent_state):\n",
        "    logger.debug(f\"agent_state type: {type(agent_state)}, value: {agent_state}\")\n",
        "    agent = agent_state if isinstance(agent_state, FinanceAgent) else FinanceAgent()\n",
        "    output = agent.respond(user_input)\n",
        "    chat_history = chat_history or []\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": output})\n",
        "    return \"\", chat_history, agent, agent.list_goals(), agent.get_budget_summary()\n",
        "\n",
        "def reset_chat(chat_history, agent_state):\n",
        "    logger.debug(f\"agent_state type: {type(agent_state)}, value: {agent_state}\")\n",
        "    agent = agent_state if isinstance(agent_state, FinanceAgent) else FinanceAgent()\n",
        "    msg = agent.reset()\n",
        "    chat_history = [{\"role\": \"assistant\", \"content\": msg}]\n",
        "    return chat_history, agent, agent.list_goals(), agent.get_budget_summary()\n",
        "\n",
        "def example_prompt(prompt, chat_history, agent_state):\n",
        "    return user_interaction(prompt, chat_history, agent_state)\n",
        "\n",
        "# Model initialization for google/flan-t5-base\n",
        "try:\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "    model_base = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
        "    model = pipeline(\"text2text-generation\", model=model_base, tokenizer=tokenizer)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Model loading failed: {e}\")\n",
        "    model = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "mXqF-UnGK2Ib",
        "outputId": "fe260493-a100-4fe6-f519-9f547c71cda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://90073500b0db38f9e7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://90073500b0db38f9e7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Launch UI\n",
        "try:\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            # 💰 Personal Finance Assistant\n",
        "            Plan your financial future! Add goals, estimate savings, or ask for advice.\n",
        "            **Examples**: 'add goal vacation 1000 12', 'list goals', 'estimate savings 3000 2500', 'How can I save for goals?'\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            # Main chat area\n",
        "            with gr.Column(scale=3):\n",
        "                user_input = gr.Textbox(\n",
        "                    placeholder=\"Type your question or command (e.g., 'add goal vacation 1000 12')\",\n",
        "                    label=\"Your Input\"\n",
        "                )\n",
        "                with gr.Row():\n",
        "                    send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
        "                    reset_btn = gr.Button(\"Reset Chat\", variant=\"secondary\")\n",
        "                chat = gr.Chatbot(type=\"messages\", label=\"Chat with Your Finance Coach\", height=400)\n",
        "\n",
        "            # Sidebar for goals and budget\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### Your Financial Snapshot\")\n",
        "                goals_display = gr.Textbox(label=\"Saved Goals\", lines=5, interactive=False)\n",
        "                budget_display = gr.Textbox(label=\"Budget Summary\", lines=3, interactive=False)\n",
        "                gr.Markdown(\"### Try These Prompts\")\n",
        "                with gr.Column():\n",
        "                    example_btn1 = gr.Button(\"Add a Goal\")\n",
        "                    example_btn2 = gr.Button(\"List Goals\")\n",
        "                    example_btn3 = gr.Button(\"Estimate Savings\")\n",
        "                    example_btn4 = gr.Button(\"Save for Goals\")\n",
        "                    example_btn5 = gr.Button(\"Stay Motivated\")\n",
        "\n",
        "        # Help section\n",
        "        with gr.Accordion(\"How to Use\", open=False):\n",
        "            gr.Markdown(\"\"\"\n",
        "            - **Add a Goal**: Use 'add goal name amount [months]' (e.g., 'add goal vacation 1000 12').\n",
        "            - **List Goals**: Type 'list goals' to see your saved goals.\n",
        "            - **Estimate Savings**: Use 'estimate savings income expenses' (e.g., 'estimate savings 3000 2500').\n",
        "            - **Ask Questions**: Try 'How can I save for goals?' or 'How do I stay motivated to stick to my budget?'.\n",
        "            - **Reset**: Click 'Reset Chat' to start over.\n",
        "            \"\"\")\n",
        "\n",
        "        agent_state = gr.State(FinanceAgent())\n",
        "\n",
        "        # Event handlers\n",
        "        send_btn.click(\n",
        "            fn=user_interaction,\n",
        "            inputs=[user_input, chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        reset_btn.click(\n",
        "            fn=reset_chat,\n",
        "            inputs=[chat, agent_state],\n",
        "            outputs=[chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        example_btn1.click(\n",
        "            fn=example_prompt,\n",
        "            inputs=[gr.State(value=\"add goal vacation 1000 12\"), chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        example_btn2.click(\n",
        "            fn=example_prompt,\n",
        "            inputs=[gr.State(value=\"list goals\"), chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        example_btn3.click(\n",
        "            fn=example_prompt,\n",
        "            inputs=[gr.State(value=\"estimate savings 3000 2500\"), chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        example_btn4.click(\n",
        "            fn=example_prompt,\n",
        "            inputs=[gr.State(value=\"How can I save for goals?\"), chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "        example_btn5.click(\n",
        "            fn=example_prompt,\n",
        "            inputs=[gr.State(value=\"How do I stay motivated to stick to my budget?\"), chat, agent_state],\n",
        "            outputs=[user_input, chat, agent_state, goals_display, budget_display]\n",
        "        )\n",
        "\n",
        "    demo.launch(debug=True, share=True)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Gradio launch failed: {e}\")\n",
        "    print(f\"Error launching Gradio: {e}. Restart runtime and reinstall dependencies if needed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}